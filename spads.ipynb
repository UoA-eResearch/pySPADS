{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "from PyEMD import CEEMDAN, Visualisation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d83509c91dcc573"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Notes\n",
    "The final program will likely be a CLI with arguments, some of the options should be:\n",
    "- Input data\n",
    "- Output data\n",
    "- Whether to interpolate over missing data (initially linear)\n",
    "- Whether to reject components which are primarily noise (with note that this may not be valid with CEEMDAN)\n",
    "    - Apriori or aposteriori test? \n",
    "- Tolerance when matching components by frequency\n",
    "- Whether to allow input components to be used in multiple output components\n",
    "- Time range for training/testing/prediction data\n",
    "- Noise values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4cb5405cb41ca032"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load data\n",
    "# TODO - note that we're not interpolating over gaps here\n",
    "from data_processing.bridge import load_shorecast, load_hindcast, load_SLP\n",
    "\n",
    "shore_df = load_shorecast()\n",
    "hind_df = load_hindcast()\n",
    "pca_df = load_SLP()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7c05347a7ee0e7b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Interpolate over NaNs in data\n",
    "def interpolate(df):\n",
    "    trange = list(range(df.index.min(), df.index.max() + 1))\n",
    "    return (\n",
    "        df\n",
    "        .reindex(trange, fill_value=np.nan)\n",
    "        .interpolate(method='linear')\n",
    "    )\n",
    "\n",
    "shore_df = interpolate(shore_df)\n",
    "hind_df = interpolate(hind_df)\n",
    "pca_df = interpolate(pca_df)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68b977d617debba5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from visualisation import paper\n",
    "\n",
    "f = paper.fig1(pca_df['PC0'], hind_df['Hs'], hind_df['Tp'], hind_df['Dir'], '2004-01-01', '2016-01-01')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca2cf39368d7c1b9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set up a list of each timeseries to decompose\n",
    "# Each item in the list is a tuple of:\n",
    "#   label, source df, source column\n",
    "series = [\n",
    "    ('output', shore_df, 'y'),\n",
    "] + [\n",
    "    (l, hind_df, l) for l in hind_df.columns\n",
    "] + [\n",
    "    (l, pca_df, l) for l in pca_df.columns\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "921cf5aa5a0138f2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set up CEEMD driver\n",
    "NR = 100\n",
    "ns = np.arange(0.1, 0.5, .05)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1c80b31ee5b5254"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Individually decompose each signal\n",
    "folder = 'output/imfs'\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "for label, df, col in series:\n",
    "    file = f'{folder}/{label}_{25}.csv'\n",
    "    if os.path.exists(file):\n",
    "        print(f'Skipping {label}')\n",
    "    else:\n",
    "        print(f'Decomposing {label}')\n",
    "        ceemd = CEEMDAN(trails=NR, epsilon=0.2, processes=8, parallel=True)\n",
    "        imfs = ceemd.ceemdan(df[col].to_numpy(), df.index.to_numpy(), progress=True)\n",
    "        imfs_df = pd.DataFrame(imfs.T, index=df.index)\n",
    "        imfs_df.to_csv(file)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "466a5f6c8a74d8d9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load all the IMFs\n",
    "folder = 'output/imfs'\n",
    "all_imfs = {}\n",
    "for label, _, _ in series:\n",
    "    file = f'{folder}/{label}_{25}.csv'\n",
    "    all_imfs[label] = pd.read_csv(file, index_col=0)\n",
    "\n",
    "    # Column names are strings, convert to ints\n",
    "    all_imfs[label].columns = all_imfs[label].columns.astype(int)    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a9ce0031f16e16d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot the IMFs\n",
    "from visualisation.imfs import plot_imfs\n",
    "\n",
    "folder = 'output/plots/imfs'\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "for label, imf_df in tqdm(all_imfs.items(), desc='Plotting IMFs'):\n",
    "    plot_imfs(imf_df.to_numpy().T, label, f'{folder}/{label}.png')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b2b23c2b2505167"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Reject components which are primarily noise\n",
    "# Note that this might not be valid when applied to the result of CEEMDAN (rather than EMD), so it should be optional\n",
    "from PyEMD.checks import whitenoise_check\n",
    "for label, imf_df in all_imfs.items():\n",
    "    print(f'Checking {label}')\n",
    "    sig = whitenoise_check(imf_df.to_numpy().T) #, test_name='apriori')\n",
    "    rejects = [k for k, v in sig.items() if v == 0]\n",
    "    print(f'Rejecting: {rejects}')\n",
    "    all_imfs[label] = imf_df.drop(columns=[i-1 for i in rejects])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9c2bf1a6e65450a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Number of components in each signal\n",
    "print('Number of component IMFs in each signal:')\n",
    "for label, imf_df in all_imfs.items():\n",
    "    print(f'{label:>12}: {imf_df.shape[1]}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d066e976c308a1e8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Match up components in input/output by frequency\n",
    "from data_processing.significance import maxima\n",
    "\n",
    "# Get the maxima of each component\n",
    "max_imfs = max([imf_df.shape[1] for imf_df in all_imfs.values()])\n",
    "freq_df = pd.DataFrame(columns=all_imfs.keys(), index=list(range(max_imfs)))\n",
    "for label, imf_df in all_imfs.items():\n",
    "    t_range = imf_df.index.max() - imf_df.index.min()\n",
    "    # Frequency of each component, in cycles per year\n",
    "    freq_df[label] = 365 * imf_df.apply(maxima, axis=0) / t_range\n",
    "\n",
    "freq_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2db8d9ef34422366"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(all_imfs['output'].columns)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46d4df841807d41d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig2 = paper.fig2(shore_df['y'], all_imfs['output'], '1999-01-01', '2017-01-01')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8926ead5ed15f9ca"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig3 = paper.fig3(all_imfs, '1999-01-01', '2017-01-01')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21bdef4be19352a6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Find the closest match for each component in output\n",
    "import warnings\n",
    "\n",
    "input_cols = set(freq_df.columns) - {'output'}\n",
    "output_index = all_imfs['output'].columns.tolist()\n",
    "nearest_freq = pd.DataFrame(columns=list(input_cols), index=output_index)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "    for label in input_cols:\n",
    "        nearest_freq[label] = freq_df['output'].apply(lambda x: (freq_df[label] - x).abs().argmin(skipna=True))\n",
    "\n",
    "nearest_freq"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54790340e773bd49"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check if difference is within tolerance\n",
    "tolerance = 0.25\n",
    "diff_df = pd.DataFrame(columns=list(input_cols), index=output_index)\n",
    "for label in input_cols:\n",
    "    diff = freq_df.loc[output_index, 'output'].reset_index(drop=True) - freq_df.loc[nearest_freq[label], label].reset_index(drop=True)\n",
    "    diff.index = output_index\n",
    "    diff_df[label] = diff \n",
    "\n",
    "diff_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc0c696bdacf5745"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Relative error\n",
    "rel_diff_df = pd.DataFrame(columns=list(input_cols), index=output_index)\n",
    "for label in input_cols:\n",
    "    rel_diff_df[label] = (diff_df[label] / freq_df['output']).abs()\n",
    "\n",
    "# If output has a component with frequency 0, then we can't calculate relative error\n",
    "# Instead, check that the input component is < tolerance x next lowest frequency output component\n",
    "if freq_df['output'].min() == 0:\n",
    "    print('Warning: output has a component with frequency 0, comparing input component to next lowest frequency output component')\n",
    "    zero_index = freq_df['output'].argmin()\n",
    "    next_lowest = freq_df.loc[freq_df['output'] > 0, 'output'].min()\n",
    "    for label in input_cols:\n",
    "        rel_diff_df.loc[zero_index, label] = abs(diff_df.loc[zero_index, label] / next_lowest)\n",
    "\n",
    "rel_diff_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7287e0e7e530b36"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check that each output component has some valid inputs\n",
    "valid_components = (rel_diff_df < tolerance).sum(axis=1)\n",
    "if any(valid_components == 0):\n",
    "    raise ValueError(f'No valid input components for output components: {valid_components[valid_components == 0].index}')\n",
    "\n",
    "if any(valid_components < 3):\n",
    "    print(f'Warning: some output components have less than 3 valid input components: {valid_components[valid_components < 3].index}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eda87c917df7bef8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rel_diff_df < tolerance"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32d4ce6ee9dddfe9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Show the components which are used for each output component\n",
    "print('Components used for each output component:')\n",
    "for i in output_index:\n",
    "    print(f'{i:>5} : {np.sum(rel_diff_df.loc[i] < tolerance)}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0161ebb7763869b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_imfs['output']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "689aee8bf98465ff"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO - note below - we have more output data than input, we should have truncated the output data before fitting!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "117e6cc1efb26c34"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(all_imfs['output'].index)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb5707022ab08f19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for label in input_cols:\n",
    "    imf_df = all_imfs[label]\n",
    "    # Print how many\n",
    "    index_overlap = all_imfs['output'].index.isin(imf_df.index)\n",
    "    print(sum(index_overlap))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "558761b75f096e33"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_imfs[label][all_imfs[label].index.isin(all_imfs['output'].index)]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e9e1a108357a257"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Linear regression of components to output signal\n",
    "# Note that this is much simpler if the original data interpolated over NaNs\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from optimization import mreg2, calc_SSE_all_Coef\n",
    "\n",
    "# TODO - note below - we have more output data than input, we should have truncated the output data before fitting!\n",
    "hindcast_index = all_imfs['output'].index[all_imfs['output'].index.isin(all_imfs['PC0'].index)]\n",
    "\n",
    "imf_predictions = pd.DataFrame(index=hindcast_index, columns=output_index)\n",
    "\n",
    "for i, imf in enumerate(output_index):\n",
    "    print(f'Fitting component {imf}')\n",
    "    X = pd.DataFrame(index=hindcast_index)\n",
    "    for label in input_cols:\n",
    "        if rel_diff_df.loc[imf, label] < tolerance:\n",
    "            # X[label] = all_imfs[label].iloc[:, nearest_freq.loc[imf, label]]\n",
    "            X[label] = all_imfs[label].loc[all_imfs[label].index.isin(hindcast_index), nearest_freq.loc[imf, label]]\n",
    "    y = all_imfs['output'].loc[hindcast_index, imf]\n",
    "    reg = LinearRegression().fit(X, y)\n",
    "    print(f'R^2: {reg.score(X, y)}')\n",
    "    print(f'Coefficients: {reg.coef_}')\n",
    "    coefs = mreg2(y,X)\n",
    "    print(coefs)\n",
    "    print(f'Intercept: {reg.intercept_}')\n",
    "    # Plot the fit\n",
    "    plt.figure()\n",
    "    plt.plot(y, label='output')\n",
    "    plt.plot(y.index, reg.predict(X), label='fit')\n",
    "    mreg_pred = np.sum([X[c] * coefs[i] for i, c in enumerate(X.columns)], axis=0)\n",
    "    plt.plot(y.index, mreg_pred, label='mreg')\n",
    "    imf_predictions.loc[:, imf] = reg.predict(X)\n",
    "    plt.legend()\n",
    "    plt.title(f'Component {imf}')\n",
    "    plt.show()\n",
    "    print('\\n\\n')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "906b5b86fcec2be"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reg.coef_"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54a5a52828f42dc8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mreg_pred = np.sum([X[c] * coefs[i] for i, c in enumerate(X.columns)], axis=0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d57ff4a2ed070af"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "46463a5715cbc599"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig4 = paper.fig4(shore_df['y'], imf_predictions, '2010-01-01', '2017-01-01')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7054df7f1d5dc84a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from data_processing.bridge import datenum_to_datetime\n",
    "# TODO - note that above covers 1998-, paper uses only 2010- data\n",
    "datenum_to_datetime(737000)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ebb310c682f4776d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: \n",
    "#   repeat the process for other noise values (and average?)\n",
    "#   tweak tolerance, noises, other settings?\n",
    "#   check regression implementation\n",
    "#   "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a02894060b6a5115"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
