{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "from PyEMD import CEEMDAN, Visualisation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d83509c91dcc573"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Notes\n",
    "The final program will likely be a CLI with arguments, some of the options should be:\n",
    "- Input data\n",
    "- Output data\n",
    "- Whether to interpolate over missing data (initially linear)\n",
    "- Whether to reject components which are primarily noise (with note that this may not be valid with CEEMDAN)\n",
    "    - Apriori or aposteriori test? \n",
    "- Tolerance when matching components by frequency\n",
    "- Time range for training/testing/prediction data\n",
    "- Noise values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4cb5405cb41ca032"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load data\n",
    "# TODO - note that we're not interpolating over gaps here\n",
    "from data_processing.bridge import load_shorecast, load_hindcast, load_SLP\n",
    "\n",
    "shore_df = load_shorecast()\n",
    "hind_df = load_hindcast()\n",
    "pca_df = load_SLP()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7c05347a7ee0e7b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set up a list of each timeseries to decompose\n",
    "# Each item in the list is a tuple of:\n",
    "#   label, source df, source column\n",
    "series = [\n",
    "    ('output', shore_df, 'y'),\n",
    "] + [\n",
    "    (l, hind_df, l) for l in hind_df.columns\n",
    "] + [\n",
    "    (l, pca_df, l) for l in pca_df.columns\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "921cf5aa5a0138f2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set up CEEMD driver\n",
    "NR = 100\n",
    "ns = np.arange(0.1, 0.5, .05)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1c80b31ee5b5254"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Individually decompose each signal\n",
    "folder = 'output/imfs'\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "for label, df, col in series:\n",
    "    file = f'{folder}/{label}.csv'\n",
    "    if os.path.exists(file):\n",
    "        print(f'Skipping {label}')\n",
    "    else:\n",
    "        print(f'Decomposing {label}')\n",
    "        ceemd = CEEMDAN(trails=NR, epsilon=ns[0], processes=8, parallel=True)\n",
    "        imfs = ceemd.ceemdan(df[col].to_numpy(), df.index.to_numpy(), progress=True)\n",
    "        imfs_df = pd.DataFrame(imfs.T, index=df.index)\n",
    "        imfs_df.to_csv(file)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "466a5f6c8a74d8d9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load all the IMFs\n",
    "all_imfs = {}\n",
    "for label, _, _ in series:\n",
    "    file = f'{folder}/{label}.csv'\n",
    "    all_imfs[label] = pd.read_csv(file, index_col=0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a9ce0031f16e16d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Reject components which are primarily noise\n",
    "# Note that this might not be valid when applied to the result of CEEMDAN (rather than EMD), so it should be optional\n",
    "from PyEMD.checks import whitenoise_check\n",
    "for label, imf_df in all_imfs.items():\n",
    "    print(f'Checking {label}')\n",
    "    sig = whitenoise_check(imf_df.to_numpy().T) #, test_name='apriori')\n",
    "    rejects = [k for k, v in sig.items() if v == 0]\n",
    "    print(f'Rejecting: {rejects}')\n",
    "    all_imfs[label] = imf_df.drop(columns=[str(i-1) for i in rejects])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9c2bf1a6e65450a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Match up components in input/output by frequency"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c79fe15dc9aa5e9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Linear regression of components to output signal"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "906b5b86fcec2be"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Recreate output signal"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef658b026865c69d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
